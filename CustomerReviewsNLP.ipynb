{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "### Customer Review model\n",
    "\n",
    "In this task, the goal is to predict the overall rating of customers using the review and summary information.\n",
    "\n",
    "### Task list\n",
    "Data exploration, data cleaning and feature engineering. Remember to comment each step properly.\n",
    "Explanatory analysis. Include key insights in the presentation\n",
    "Modelling/Training\n",
    "Prepare a presentation and present the analysis. Use visualisations and tell compelling stories. Tell us what is the message(s) for the business? What actionable insights you can provide to the business?\n",
    "\n",
    "### Required Output\n",
    "Fully commented code\n",
    "Modelling dataset (json file)\n",
    "Visualisation tool files (if anything)\n",
    "Slides of presentations, including but not limited to:\n",
    "Problem statement, Assumptions, Hypotheses\n",
    "Exploratory analysis\n",
    "Modelling approach\n",
    "Results\n",
    "Model performance measures\n",
    "Business audience performance measures\n",
    "Insights\n",
    "Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "- This section includes loading of the data, understanding basic description of the data; followed by cleanup & imputations if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pyplot\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score,precision_score,recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "# import pickle\n",
    "\n",
    "# loading keras packages\n",
    "from keras.utils import np_utils\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, SpatialDropout1D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data is: (10261, 9)\n"
     ]
    }
   ],
   "source": [
    "# Loading at the data and looking at the shape\n",
    "\n",
    "review_data = pd.read_json('data/Musical_Instruments_5.json', lines=True)\n",
    "print('Shape of data is:', review_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2IBPI20UZIR0U</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>cassandra tu \"Yeah, well, that's just like, u...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Not much to write about here, but it does exac...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>1393545600</td>\n",
       "      <td>02 28, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A14VAT5EAX3D9S</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Jake</td>\n",
       "      <td>[13, 14]</td>\n",
       "      <td>The product does exactly as it should and is q...</td>\n",
       "      <td>5</td>\n",
       "      <td>Jake</td>\n",
       "      <td>1363392000</td>\n",
       "      <td>03 16, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A195EZSQDW3E21</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Rick Bennette \"Rick Bennette\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>The primary job of this device is to block the...</td>\n",
       "      <td>5</td>\n",
       "      <td>It Does The Job Well</td>\n",
       "      <td>1377648000</td>\n",
       "      <td>08 28, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2C00NNG1ZQQG2</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>RustyBill \"Sunday Rocker\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Nice windscreen protects my MXL mic and preven...</td>\n",
       "      <td>5</td>\n",
       "      <td>GOOD WINDSCREEN FOR THE MONEY</td>\n",
       "      <td>1392336000</td>\n",
       "      <td>02 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A94QU4C90B1AX</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>SEAN MASLANKA</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This pop filter is great. It looks and perform...</td>\n",
       "      <td>5</td>\n",
       "      <td>No more pops when I record my vocals.</td>\n",
       "      <td>1392940800</td>\n",
       "      <td>02 21, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  \\\n",
       "0  A2IBPI20UZIR0U  1384719342   \n",
       "1  A14VAT5EAX3D9S  1384719342   \n",
       "2  A195EZSQDW3E21  1384719342   \n",
       "3  A2C00NNG1ZQQG2  1384719342   \n",
       "4   A94QU4C90B1AX  1384719342   \n",
       "\n",
       "                                       reviewerName   helpful  \\\n",
       "0  cassandra tu \"Yeah, well, that's just like, u...    [0, 0]   \n",
       "1                                              Jake  [13, 14]   \n",
       "2                     Rick Bennette \"Rick Bennette\"    [1, 1]   \n",
       "3                         RustyBill \"Sunday Rocker\"    [0, 0]   \n",
       "4                                     SEAN MASLANKA    [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Not much to write about here, but it does exac...        5   \n",
       "1  The product does exactly as it should and is q...        5   \n",
       "2  The primary job of this device is to block the...        5   \n",
       "3  Nice windscreen protects my MXL mic and preven...        5   \n",
       "4  This pop filter is great. It looks and perform...        5   \n",
       "\n",
       "                                 summary  unixReviewTime   reviewTime  \n",
       "0                                   good      1393545600  02 28, 2014  \n",
       "1                                   Jake      1363392000  03 16, 2013  \n",
       "2                   It Does The Job Well      1377648000  08 28, 2013  \n",
       "3          GOOD WINDSCREEN FOR THE MONEY      1392336000  02 14, 2014  \n",
       "4  No more pops when I record my vocals.      1392940800  02 21, 2014  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID        object\n",
       "asin              object\n",
       "reviewerName      object\n",
       "helpful           object\n",
       "reviewText        object\n",
       "overall            int64\n",
       "summary           object\n",
       "unixReviewTime     int64\n",
       "reviewTime        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at individual features\n",
    "review_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 67.61524217912485),\n",
       " (4, 20.309911314686676),\n",
       " (3, 7.523633174154567),\n",
       " (2, 2.4364097066562715),\n",
       " (1, 2.1148036253776437)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking the count of unique target values\n",
    "\n",
    "sns.countplot(review_data['overall']);\n",
    "c = Counter(review_data['overall'])\n",
    "[(i, c[i] / len(review_data['overall']) * 100.0) for i, count in c.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID       1429\n",
       "asin              900\n",
       "reviewerName     1397\n",
       "reviewText      10255\n",
       "overall             5\n",
       "summary          8852\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for unique values\n",
    "\n",
    "review_data.loc[:,['reviewerID', 'asin', 'reviewerName', 'reviewText', 'overall', 'summary']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID         0\n",
       "asin               0\n",
       "reviewerName      27\n",
       "helpful            0\n",
       "reviewText         0\n",
       "overall            0\n",
       "summary            0\n",
       "unixReviewTime     0\n",
       "reviewTime         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking nan values across dataset\n",
    "\n",
    "review_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing uneccessary columns for now\n",
    "\n",
    "review_data.drop(labels=['reviewerID', 'asin', 'reviewerName', 'helpful', 'unixReviewTime', 'reviewTime'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>good Not much to write about here, but it does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Jake The product does exactly as it should and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>It Does The Job Well The primary job of this d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>GOOD WINDSCREEN FOR THE MONEY Nice windscreen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>No more pops when I record my vocals. This pop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall                                               text\n",
       "0        5  good Not much to write about here, but it does...\n",
       "1        5  Jake The product does exactly as it should and...\n",
       "2        5  It Does The Job Well The primary job of this d...\n",
       "3        5  GOOD WINDSCREEN FOR THE MONEY Nice windscreen ...\n",
       "4        5  No more pops when I record my vocals. This pop..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining summary and  reviewText\n",
    "\n",
    "review_data['text'] = review_data['summary'] + ' ' + review_data['reviewText']\n",
    "review_data.drop(labels=['summary', 'reviewText'], axis=1, inplace=True)\n",
    "review_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10261, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Observations:\n",
    "\n",
    "- There are a total of 10261 records and 9 features. However, for this problem we shall be taking into account the summary, reviewtext and overall.\n",
    "- There is noticable imbalance 5 and 4 ratings at 87 percent and the remaining 13 percent are covered with 1,2,3 ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Jake The product does exactly as it should and is quite affordable.I did not realized it was double screened until it arrived, so it was even better than I had expected.As an added bonus, one of the screens carries a small hint of the smell of an old grape candy I used to buy, so for reminiscent's sake, I cannot stop putting the pop filter next to my nose and smelling it after recording. :DIf you needed a pop filter, this will work just as well as the expensive ones, and it may even come with a pleasing aroma like mine did!Buy this product! :]\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data['text'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jake the product does exactly as it should and is quite affordable i did not realized it was double screened until it arrived  so it was even better than i had expected as an added bonus  one of the screens carries a small hint of the smell of an old grape candy i used to buy  so for reminiscent s sake  i cannot stop putting the pop filter next to my nose and smelling it after recording   dif you needed a pop filter  this will work just as well as the expensive ones  and it may even come with a pleasing aroma like mine did buy this product    '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to remove punctuations\n",
    "# string.punctuation\n",
    "def remove_punctuation(text):\n",
    "#     no_punct = \"\".join([c for c in text if c not in string.punctuation])\n",
    "#     return no_punct\n",
    "    string1 = text.lower()\n",
    "    translation_table = dict.fromkeys(map(ord, string.punctuation),' ')\n",
    "    string2 = string1.translate(translation_table)\n",
    "    return string2\n",
    "\n",
    "review_data['text'] = review_data['text'].apply(lambda x: remove_punctuation(x))\n",
    "review_data['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jake  product  exactly      quite affordable    realized   double screened   arrived     even better    expected   added bonus  one   screens carries  small hint   smell   old grape candy  used  buy    reminiscent  sake   cannot stop putting  pop filter next   nose  smelling   recording   dif  needed  pop filter    work   well   expensive ones    may even come   pleasing aroma like mine  buy  product    '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to remove stop words\n",
    "# stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "#     return [w for w in text if w not in stopwords.words('english')]\n",
    "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
    "    string2 = pattern.sub(' ', text)\n",
    "    return string2\n",
    "\n",
    "review_data['text'] = review_data['text'].apply(lambda x: remove_stopwords(x))\n",
    "review_data['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jake',\n",
       " 'product',\n",
       " 'exactly',\n",
       " 'quite',\n",
       " 'affordable',\n",
       " 'realized',\n",
       " 'double',\n",
       " 'screened',\n",
       " 'arrived',\n",
       " 'even',\n",
       " 'better',\n",
       " 'expected',\n",
       " 'added',\n",
       " 'bonus',\n",
       " 'one',\n",
       " 'screens',\n",
       " 'carries',\n",
       " 'small',\n",
       " 'hint',\n",
       " 'smell',\n",
       " 'old',\n",
       " 'grape',\n",
       " 'candy',\n",
       " 'used',\n",
       " 'buy',\n",
       " 'reminiscent',\n",
       " 'sake',\n",
       " 'can',\n",
       " 'not',\n",
       " 'stop',\n",
       " 'putting',\n",
       " 'pop',\n",
       " 'filter',\n",
       " 'next',\n",
       " 'nose',\n",
       " 'smelling',\n",
       " 'recording',\n",
       " 'dif',\n",
       " 'needed',\n",
       " 'pop',\n",
       " 'filter',\n",
       " 'work',\n",
       " 'well',\n",
       " 'expensive',\n",
       " 'ones',\n",
       " 'may',\n",
       " 'even',\n",
       " 'come',\n",
       " 'pleasing',\n",
       " 'aroma',\n",
       " 'like',\n",
       " 'mine',\n",
       " 'buy',\n",
       " 'product']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to tokenize\n",
    "def tokenize_words(text):\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "review_data['text'] = review_data['text'].apply(lambda x: tokenize_words(x.lower()))\n",
    "review_data['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#Lemmatization\n",
    "def lemmatize_words(data_str):\n",
    "# expects a string\n",
    "    list_pos = 0\n",
    "    cleaned_str = ''\n",
    "    final_text=[]\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    stop = set(stopwords.words('english'))\n",
    "    punc = list(string.punctuation)\n",
    "    stop.update(punc)\n",
    "    for i in data_str:\n",
    "        if i.strip().lower() not in stop:\n",
    "            pos = pos_tag([i.strip()])\n",
    "            if get_simple_pos(pos[0][1]) is None:\n",
    "                pass\n",
    "            else:\n",
    "                word = lmtzr.lemmatize(i.strip(),get_simple_pos(pos[0][1]))\n",
    "                final_text.append(word.lower())\n",
    "    return \" \".join(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jake product exactly quite affordable realize double screen arrive even well expect add bonus screen carry small hint smell old grape candy use buy reminiscent sake stop put pop filter next nose smell record dif need pop filter work well expensive one even come please aroma mine buy product'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data['text'] = review_data['text'].apply(lambda x: lemmatize_words(x))\n",
    "review_data['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000)\n",
    "# tfidf = TfidfVectorizer()\n",
    "X_data = tfidf.fit_transform(review_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10261, 1000)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data\n",
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = review_data['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.25, random_state= 45, stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_copy = X_train.copy()\n",
    "# y_train_copy = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Applying oversampling of data\n",
    "# # summarize distribution\n",
    "# counter = Counter(y_train_copy)\n",
    "# for k,v in counter.items():\n",
    "#     per = v / len(y_train_copy) * 100\n",
    "#     print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# # plot the distribution\n",
    "# pyplot.bar(counter.keys(), counter.values())\n",
    "# pyplot.show()\n",
    "\n",
    "# # resample = SMOTE()\n",
    "# # resample = SMOTETomek()\n",
    "# resample = SMOTEENN()\n",
    "# X_train, y_train = resample.fit_resample(X_train_copy, y_train_copy)\n",
    "\n",
    "# # summarize distribution\n",
    "# counter = Counter(y_train)\n",
    "# for k,v in counter.items():\n",
    "#     per = v / len(y_train) * 100\n",
    "#     print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# # plot the distribution\n",
    "# pyplot.bar(counter.keys(), counter.values())\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10261, 700)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:50:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# Instatiation, fitting and predictions\n",
    "\n",
    "xgb_ = xgb.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'multi:softmax',\n",
    " nthread=4,\n",
    " seed= 45)\n",
    "\n",
    "xgb_.fit(X_train, y_train)\n",
    "predictions = xgb_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.11      0.17        54\n",
      "           2       0.21      0.05      0.08        63\n",
      "           3       0.49      0.18      0.26       193\n",
      "           4       0.40      0.22      0.28       521\n",
      "           5       0.74      0.93      0.83      1735\n",
      "\n",
      "    accuracy                           0.69      2566\n",
      "   macro avg       0.44      0.30      0.32      2566\n",
      "weighted avg       0.63      0.69      0.64      2566\n",
      "\n",
      "[[   6    3    5    5   35]\n",
      " [   2    3   10   12   36]\n",
      " [   1    5   34   53  100]\n",
      " [   3    1   15  114  388]\n",
      " [   4    2    6  103 1620]]\n",
      "Accuracy :  69.25 %\n",
      "f1_score :  0.642\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "xgb_f1 = round(f1_score(y_test, predictions, average= 'weighted'), 3)\n",
    "xgb_accuracy = round((accuracy_score(y_test, predictions) * 100), 2)\n",
    "\n",
    "print(\"Accuracy : \" , xgb_accuracy , \"%\")\n",
    "print(\"f1_score : \" , xgb_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting target into dummies\n",
    "\n",
    "y_train_updated = pd.get_dummies(y_train).values\n",
    "y_test_updated = pd.get_dummies(y_test).values\n",
    "num_classes = y_test_updated.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 50)                788900    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 799,355\n",
      "Trainable params: 799,355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the LSTM model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input - Layer\n",
    "model.add(Dense(50, activation = \"relu\", input_shape=(15777, )))\n",
    "\n",
    "# Hidden - Layers\n",
    "model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "\n",
    "# Output- Layer\n",
    "model.add(Dense(5, activation = \"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "# model.add(Dense(units = 75 , activation = 'relu' , input_dim = X_train.shape[1]))\n",
    "# model.add(Dense(units = 50 , activation = 'relu'))\n",
    "# model.add(Dense(units = 25 , activation = 'relu'))\n",
    "# model.add(Dense(units = 10 , activation = 'relu')) \n",
    "# model.add(Dense(units = 5, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7695 samples, validate on 2566 samples\n",
      "Epoch 1/10\n",
      "7695/7695 [==============================] - 5s 674us/step - loss: 1.1056 - accuracy: 0.6721 - val_loss: 0.9062 - val_accuracy: 0.6761\n",
      "Epoch 2/10\n",
      "7695/7695 [==============================] - 5s 607us/step - loss: 0.8330 - accuracy: 0.6762 - val_loss: 0.8249 - val_accuracy: 0.6761\n",
      "Epoch 3/10\n",
      "7695/7695 [==============================] - 5s 591us/step - loss: 0.7006 - accuracy: 0.6856 - val_loss: 0.8773 - val_accuracy: 0.6836\n",
      "Epoch 4/10\n",
      "7695/7695 [==============================] - 5s 597us/step - loss: 0.6079 - accuracy: 0.7376 - val_loss: 0.9893 - val_accuracy: 0.6660\n",
      "Epoch 5/10\n",
      "7695/7695 [==============================] - 5s 599us/step - loss: 0.5183 - accuracy: 0.7923 - val_loss: 1.1593 - val_accuracy: 0.6399\n",
      "Epoch 6/10\n",
      "7695/7695 [==============================] - 5s 604us/step - loss: 0.4342 - accuracy: 0.8301 - val_loss: 1.3204 - val_accuracy: 0.6122\n",
      "Epoch 7/10\n",
      "7695/7695 [==============================] - 5s 604us/step - loss: 0.3697 - accuracy: 0.8613 - val_loss: 1.4482 - val_accuracy: 0.6216\n",
      "Epoch 8/10\n",
      "7695/7695 [==============================] - 5s 606us/step - loss: 0.3112 - accuracy: 0.8817 - val_loss: 1.7509 - val_accuracy: 0.6154\n",
      "Epoch 9/10\n",
      "7695/7695 [==============================] - 5s 621us/step - loss: 0.2745 - accuracy: 0.8962 - val_loss: 1.7353 - val_accuracy: 0.6333\n",
      "Epoch 10/10\n",
      "7695/7695 [==============================] - 5s 636us/step - loss: 0.2408 - accuracy: 0.9101 - val_loss: 1.9372 - val_accuracy: 0.6278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x25e7ae54da0>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_updated, validation_data=(X_test, y_test_updated), epochs=epochs, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.78%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test_updated, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_probs = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhat_classes = model.predict_classes(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 7.8678131e-06, 6.6501349e-02,\n",
       "        7.1559179e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 3.5762787e-07, 1.8999845e-02,\n",
       "        9.7059107e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 9.2655420e-05,\n",
       "        9.9999738e-01],\n",
       "       ...,\n",
       "       [1.0823697e-02, 2.5938570e-02, 3.1870449e-01, 5.5544645e-02,\n",
       "        1.5549064e-03],\n",
       "       [0.0000000e+00, 0.0000000e+00, 3.2246113e-05, 6.0008734e-02,\n",
       "        8.8592446e-01],\n",
       "       [4.0739775e-05, 1.8161535e-04, 1.3472199e-02, 3.2758981e-01,\n",
       "        1.1488302e-02]], dtype=float32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argmax(yhat_probs, axis=-1)\n",
    "yhat_probs = np.zeros( yhat_probs.shape )\n",
    "yhat_probs[ np.arange(yhat_probs.shape[0]), idx] = 1\n",
    "yhat_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reduce to 1d array\n",
    "# yhat_probs = yhat_probs[:, 0]\n",
    "# # yhat_classes = yhat_classes[:, 0]\n",
    "# yhat_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 1       0.00      0.00      0.00        54\n",
      "     class 2       0.00      0.00      0.00        63\n",
      "     class 3       0.29      0.33      0.31       193\n",
      "     class 4       0.32      0.36      0.34       521\n",
      "     class 5       0.78      0.78      0.78      1735\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      2566\n",
      "   macro avg       0.28      0.30      0.29      2566\n",
      "weighted avg       0.61      0.63      0.62      2566\n",
      " samples avg       0.63      0.63      0.63      2566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['class 1', 'class 2', 'class 3', 'class 4','class 5']\n",
    "print(classification_report(y_test_updated, yhat_probs ,target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print('Accuracy: %f' % accuracy)\n",
    "# # precision tp / (tp + fp)\n",
    "# precision = precision_score(y_test, yhat_classes,average = None)\n",
    "# # print('Precision: %f' % precision)\n",
    "# # recall: tp / (tp + fn)\n",
    "# recall = recall_score(y_test, yhat_classes,average = None)\n",
    "# # print('Recall: %f' % recall)\n",
    "# # f1: 2 tp / (2 tp + fp + fn)\n",
    "# f1 = f1_score(y_test, yhat_classes,average = None)\n",
    "# # print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 32)          160000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 1000, 32)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30)                7560      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 155       \n",
      "=================================================================\n",
      "Total params: 167,715\n",
      "Trainable params: 167,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Instantiating model\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "embedding_size=32\n",
    "max_words=5000\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_size, input_length=X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(30, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Label tensor:  (7695, 5)\n"
     ]
    }
   ],
   "source": [
    "# converting categorical variables in y_train to numerical variables\n",
    "y_train_dummies = pd.get_dummies(y_train).values\n",
    "print('Shape of Label tensor: ', y_train_dummies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7695/7695 [==============================] - 115s 15ms/step - loss: 1.0574 - accuracy: 0.6736\n",
      "Epoch 2/5\n",
      "7695/7695 [==============================] - 142s 18ms/step - loss: 0.9573 - accuracy: 0.6762\n",
      "Epoch 3/5\n",
      "7695/7695 [==============================] - 204s 27ms/step - loss: 0.9572 - accuracy: 0.6762\n",
      "Epoch 4/5\n",
      "7695/7695 [==============================] - 248s 32ms/step - loss: 0.9585 - accuracy: 0.6762\n",
      "Epoch 5/5\n",
      "7695/7695 [==============================] - 448s 58ms/step - loss: 0.9572 - accuracy: 0.6762\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "model.fit(X_train, y_train_dummies, epochs=epochs, batch_size=batch_size)\n",
    "# model.fit(X_train, y_train_dummies, epochs=epochs, batch_size=batch_size,\n",
    "#           validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "model.save('MusicalInstrumentReviews.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Label tensor:  (2566, 5)\n"
     ]
    }
   ],
   "source": [
    "# converting categorical variables in y_train to numerical variables\n",
    "y_test_dummies = pd.get_dummies(y_test).values\n",
    "print('Shape of Label tensor: ', y_test_dummies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2566/2566 [==============================] - 24s 9ms/step\n",
      "Test accuracy:  67.61496663093567 %\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('MusicalInstrumentReviews.h5')\n",
    "scores = model.evaluate(X_test, y_test_dummies)\n",
    "\n",
    "LSTM_accuracy = scores[1]*100\n",
    "\n",
    "print('Test accuracy: ', scores[1]*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 1       0.00      0.00      0.00        54\n",
      "     class 2       0.00      0.00      0.00        63\n",
      "     class 3       0.00      0.00      0.00       193\n",
      "     class 4       0.00      0.00      0.00       521\n",
      "     class 5       0.68      1.00      0.81      1735\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      2566\n",
      "   macro avg       0.14      0.20      0.16      2566\n",
      "weighted avg       0.46      0.68      0.55      2566\n",
      " samples avg       0.68      0.68      0.68      2566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yhat_probs = model.predict(X_test)\n",
    "idx = np.argmax(yhat_probs, axis=-1)\n",
    "yhat_probs = np.zeros( yhat_probs.shape )\n",
    "yhat_probs[ np.arange(yhat_probs.shape[0]), idx] = 1\n",
    "# yhat_probs\n",
    "\n",
    "target_names = ['class 1', 'class 2', 'class 3', 'class 4','class 5']\n",
    "print(classification_report(y_test_dummies, yhat_probs ,target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
