{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "### Upgrade propensity model\n",
    "\n",
    "In this task, the goal is to predict the overall rating of customers using the review and summary information.\n",
    "\n",
    "### Task list\n",
    "Data exploration, data cleaning and feature engineering. Remember to comment each step properly.\n",
    "Explanatory analysis. Include key insights in the presentation\n",
    "Modelling/Training\n",
    "Prepare a presentation and present the analysis. Use visualisations and tell compelling stories. Tell us what is the message(s) for the business? What actionable insights you can provide to the business?\n",
    "\n",
    "### Required Output\n",
    "Fully commented code\n",
    "Modelling dataset (json file)\n",
    "Visualisation tool files (if anything)\n",
    "Slides of presentations, including but not limited to:\n",
    "Problem statement, Assumptions, Hypotheses\n",
    "Exploratory analysis\n",
    "Modelling approach\n",
    "Results\n",
    "Model performance measures\n",
    "Business audience performance measures\n",
    "Insights\n",
    "Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "- This section includes loading of the data, understanding basic description of the data; followed by cleanup & imputations if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score,precision_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "# import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data is: (10261, 9)\n"
     ]
    }
   ],
   "source": [
    "# Loading at the data and looking at the shape\n",
    "\n",
    "review_data = pd.read_json('data/Musical_Instruments_5.json', lines=True)\n",
    "print('Shape of data is:', review_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2IBPI20UZIR0U</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>cassandra tu \"Yeah, well, that's just like, u...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Not much to write about here, but it does exac...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>1393545600</td>\n",
       "      <td>02 28, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A14VAT5EAX3D9S</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Jake</td>\n",
       "      <td>[13, 14]</td>\n",
       "      <td>The product does exactly as it should and is q...</td>\n",
       "      <td>5</td>\n",
       "      <td>Jake</td>\n",
       "      <td>1363392000</td>\n",
       "      <td>03 16, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A195EZSQDW3E21</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Rick Bennette \"Rick Bennette\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>The primary job of this device is to block the...</td>\n",
       "      <td>5</td>\n",
       "      <td>It Does The Job Well</td>\n",
       "      <td>1377648000</td>\n",
       "      <td>08 28, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2C00NNG1ZQQG2</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>RustyBill \"Sunday Rocker\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Nice windscreen protects my MXL mic and preven...</td>\n",
       "      <td>5</td>\n",
       "      <td>GOOD WINDSCREEN FOR THE MONEY</td>\n",
       "      <td>1392336000</td>\n",
       "      <td>02 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A94QU4C90B1AX</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>SEAN MASLANKA</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This pop filter is great. It looks and perform...</td>\n",
       "      <td>5</td>\n",
       "      <td>No more pops when I record my vocals.</td>\n",
       "      <td>1392940800</td>\n",
       "      <td>02 21, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  \\\n",
       "0  A2IBPI20UZIR0U  1384719342   \n",
       "1  A14VAT5EAX3D9S  1384719342   \n",
       "2  A195EZSQDW3E21  1384719342   \n",
       "3  A2C00NNG1ZQQG2  1384719342   \n",
       "4   A94QU4C90B1AX  1384719342   \n",
       "\n",
       "                                       reviewerName   helpful  \\\n",
       "0  cassandra tu \"Yeah, well, that's just like, u...    [0, 0]   \n",
       "1                                              Jake  [13, 14]   \n",
       "2                     Rick Bennette \"Rick Bennette\"    [1, 1]   \n",
       "3                         RustyBill \"Sunday Rocker\"    [0, 0]   \n",
       "4                                     SEAN MASLANKA    [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Not much to write about here, but it does exac...        5   \n",
       "1  The product does exactly as it should and is q...        5   \n",
       "2  The primary job of this device is to block the...        5   \n",
       "3  Nice windscreen protects my MXL mic and preven...        5   \n",
       "4  This pop filter is great. It looks and perform...        5   \n",
       "\n",
       "                                 summary  unixReviewTime   reviewTime  \n",
       "0                                   good      1393545600  02 28, 2014  \n",
       "1                                   Jake      1363392000  03 16, 2013  \n",
       "2                   It Does The Job Well      1377648000  08 28, 2013  \n",
       "3          GOOD WINDSCREEN FOR THE MONEY      1392336000  02 14, 2014  \n",
       "4  No more pops when I record my vocals.      1392940800  02 21, 2014  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID        object\n",
       "asin              object\n",
       "reviewerName      object\n",
       "helpful           object\n",
       "reviewText        object\n",
       "overall            int64\n",
       "summary           object\n",
       "unixReviewTime     int64\n",
       "reviewTime        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at individual features\n",
    "review_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking the count of unique target values\n",
    "\n",
    "sns.countplot(review_data['overall']);\n",
    "# c = Counter(review_data['overall'])\n",
    "# [(i, c[i] / len(review_data['overall']) * 100.0) for i, count in c.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID       1429\n",
       "asin              900\n",
       "reviewerName     1397\n",
       "reviewText      10255\n",
       "overall             5\n",
       "summary          8852\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for unique values\n",
    "\n",
    "review_data.loc[:,['reviewerID', 'asin', 'reviewerName', 'reviewText', 'overall', 'summary']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID         0\n",
       "asin               0\n",
       "reviewerName      27\n",
       "helpful            0\n",
       "reviewText         0\n",
       "overall            0\n",
       "summary            0\n",
       "unixReviewTime     0\n",
       "reviewTime         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking nan values across dataset\n",
    "\n",
    "review_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing uneccessary columns for now\n",
    "\n",
    "review_data.drop(labels=['reviewerID', 'asin', 'reviewerName', 'helpful', 'unixReviewTime', 'reviewTime'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>good Not much to write about here, but it does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Jake The product does exactly as it should and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>It Does The Job Well The primary job of this d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>GOOD WINDSCREEN FOR THE MONEY Nice windscreen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>No more pops when I record my vocals. This pop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall                                               text\n",
       "0        5  good Not much to write about here, but it does...\n",
       "1        5  Jake The product does exactly as it should and...\n",
       "2        5  It Does The Job Well The primary job of this d...\n",
       "3        5  GOOD WINDSCREEN FOR THE MONEY Nice windscreen ...\n",
       "4        5  No more pops when I record my vocals. This pop..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining summary and  reviewText\n",
    "\n",
    "review_data['text'] = review_data['summary'] + ' ' + review_data['reviewText']\n",
    "review_data.drop(labels=['summary', 'reviewText'], axis=1, inplace=True)\n",
    "review_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10261, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Observations:\n",
    "\n",
    "- There are a total of 10261 records and 9 features. However, for this problem we shall be taking into account the summary, reviewtext and overall.\n",
    "- There is noticable imbalance 5 and 4 ratings at 87 percent and the remaining 13 percent are covered with 1,2,3 ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Jake The product does exactly as it should and is quite affordable.I did not realized it was double screened until it arrived, so it was even better than I had expected.As an added bonus, one of the screens carries a small hint of the smell of an old grape candy I used to buy, so for reminiscent's sake, I cannot stop putting the pop filter next to my nose and smelling it after recording. :DIf you needed a pop filter, this will work just as well as the expensive ones, and it may even come with a pleasing aroma like mine did!Buy this product! :]\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data['text'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jake the product does exactly as it should and is quite affordable i did not realized it was double screened until it arrived  so it was even better than i had expected as an added bonus  one of the screens carries a small hint of the smell of an old grape candy i used to buy  so for reminiscent s sake  i cannot stop putting the pop filter next to my nose and smelling it after recording   dif you needed a pop filter  this will work just as well as the expensive ones  and it may even come with a pleasing aroma like mine did buy this product    '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to remove punctuations\n",
    "# string.punctuation\n",
    "def remove_punctuation(text):\n",
    "#     no_punct = \"\".join([c for c in text if c not in string.punctuation])\n",
    "#     return no_punct\n",
    "    string1 = text.lower()\n",
    "    translation_table = dict.fromkeys(map(ord, string.punctuation),' ')\n",
    "    string2 = string1.translate(translation_table)\n",
    "    return string2\n",
    "\n",
    "review_data['text'] = review_data['text'].apply(lambda x: remove_punctuation(x))\n",
    "review_data['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jake  product  exactly      quite affordable    realized   double screened   arrived     even better    expected   added bonus  one   screens carries  small hint   smell   old grape candy  used  buy    reminiscent  sake   cannot stop putting  pop filter next   nose  smelling   recording   dif  needed  pop filter    work   well   expensive ones    may even come   pleasing aroma like mine  buy  product    '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to remove stop words\n",
    "# stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "#     return [w for w in text if w not in stopwords.words('english')]\n",
    "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
    "    string2 = pattern.sub(' ', text)\n",
    "    return string2\n",
    "\n",
    "review_data['text'] = review_data['text'].apply(lambda x: remove_stopwords(x))\n",
    "review_data['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jake',\n",
       " 'product',\n",
       " 'exactly',\n",
       " 'quite',\n",
       " 'affordable',\n",
       " 'realized',\n",
       " 'double',\n",
       " 'screened',\n",
       " 'arrived',\n",
       " 'even',\n",
       " 'better',\n",
       " 'expected',\n",
       " 'added',\n",
       " 'bonus',\n",
       " 'one',\n",
       " 'screens',\n",
       " 'carries',\n",
       " 'small',\n",
       " 'hint',\n",
       " 'smell',\n",
       " 'old',\n",
       " 'grape',\n",
       " 'candy',\n",
       " 'used',\n",
       " 'buy',\n",
       " 'reminiscent',\n",
       " 'sake',\n",
       " 'can',\n",
       " 'not',\n",
       " 'stop',\n",
       " 'putting',\n",
       " 'pop',\n",
       " 'filter',\n",
       " 'next',\n",
       " 'nose',\n",
       " 'smelling',\n",
       " 'recording',\n",
       " 'dif',\n",
       " 'needed',\n",
       " 'pop',\n",
       " 'filter',\n",
       " 'work',\n",
       " 'well',\n",
       " 'expensive',\n",
       " 'ones',\n",
       " 'may',\n",
       " 'even',\n",
       " 'come',\n",
       " 'pleasing',\n",
       " 'aroma',\n",
       " 'like',\n",
       " 'mine',\n",
       " 'buy',\n",
       " 'product']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to tokenize\n",
    "def tokenize_words(text):\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "review_data['text'] = review_data['text'].apply(lambda x: tokenize_words(x.lower()))\n",
    "review_data['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#Lemmatization\n",
    "def lemmatize_words(data_str):\n",
    "# expects a string\n",
    "    list_pos = 0\n",
    "    cleaned_str = ''\n",
    "    final_text=[]\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    stop = set(stopwords.words('english'))\n",
    "    punc = list(string.punctuation)\n",
    "    stop.update(punc)\n",
    "    for i in data_str:\n",
    "        if i.strip().lower() not in stop:\n",
    "            pos = pos_tag([i.strip()])\n",
    "            if get_simple_pos(pos[0][1]) is None:\n",
    "                pass\n",
    "            else:\n",
    "                word = lmtzr.lemmatize(i.strip(),get_simple_pos(pos[0][1]))\n",
    "                final_text.append(word.lower())\n",
    "    return \" \".join(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jake product exactly quite affordable realize double screen arrive even well expect add bonus screen carry small hint smell old grape candy use buy reminiscent sake stop put pop filter next nose smell record dif need pop filter work well expensive one even come please aroma mine buy product'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data['text'] = review_data['text'].apply(lambda x: lemmatize_words(x))\n",
    "review_data['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>good much write exactly suppose filter pop sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>jake product exactly quite affordable realize ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>job well primary job device block breath other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>good windscreen money nice windscreen protects...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>pop record vocal pop filter great look perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10256</th>\n",
       "      <td>5</td>\n",
       "      <td>star great expect thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10257</th>\n",
       "      <td>5</td>\n",
       "      <td>long life player good economic choice think tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10258</th>\n",
       "      <td>4</td>\n",
       "      <td>good coat try coat string past include elixir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10259</th>\n",
       "      <td>4</td>\n",
       "      <td>taylor make well make elixir developed taylor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10260</th>\n",
       "      <td>4</td>\n",
       "      <td>string really quite good call perfect string r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10261 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall                                               text\n",
       "0            5  good much write exactly suppose filter pop sou...\n",
       "1            5  jake product exactly quite affordable realize ...\n",
       "2            5  job well primary job device block breath other...\n",
       "3            5  good windscreen money nice windscreen protects...\n",
       "4            5  pop record vocal pop filter great look perform...\n",
       "...        ...                                                ...\n",
       "10256        5                            star great expect thank\n",
       "10257        5  long life player good economic choice think tr...\n",
       "10258        4  good coat try coat string past include elixir ...\n",
       "10259        4  taylor make well make elixir developed taylor ...\n",
       "10260        4  string really quite good call perfect string r...\n",
       "\n",
       "[10261 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X_data = tfidf.fit_transform(review_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10261x15777 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 359658 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = review_data['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.25, random_state= 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y_train_updated = np_utils.to_categorical(y_train)\n",
    "y_test_updated = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test_updated.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units = 75 , activation = 'relu' , input_dim = X_train.shape[1]))\n",
    "model.add(Dense(units = 50 , activation = 'relu'))\n",
    "model.add(Dense(units = 25 , activation = 'relu'))\n",
    "model.add(Dense(units = 10 , activation = 'relu')) \n",
    "model.add(Dense(units = 6, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Conv2D(32, (3, 3), input_shape=X_train.shape[1:], padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Flatten())\n",
    "# model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Dense(256, kernel_constraint=maxnorm(3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Dense(128, kernel_constraint=maxnorm(3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Dense(num_classes))\n",
    "# model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "optimizer = 'Adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7695 samples, validate on 2566 samples\n",
      "Epoch 1/5\n",
      "7695/7695 [==============================] - 4s 562us/step - loss: 0.4345 - accuracy: 0.8892 - val_loss: 0.3219 - val_accuracy: 0.8965\n",
      "Epoch 2/5\n",
      "7695/7695 [==============================] - 4s 509us/step - loss: 0.2841 - accuracy: 0.8906 - val_loss: 0.2667 - val_accuracy: 0.8965\n",
      "Epoch 3/5\n",
      "7695/7695 [==============================] - 4s 482us/step - loss: 0.2036 - accuracy: 0.9093 - val_loss: 0.2495 - val_accuracy: 0.8966\n",
      "Epoch 4/5\n",
      "7695/7695 [==============================] - 3s 453us/step - loss: 0.1532 - accuracy: 0.9297 - val_loss: 0.2937 - val_accuracy: 0.8882\n",
      "Epoch 5/5\n",
      "7695/7695 [==============================] - 4s 462us/step - loss: 0.1240 - accuracy: 0.9426 - val_loss: 0.3476 - val_accuracy: 0.8851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x18c50e3fb38>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_updated, validation_data=(X_test, y_test_updated), epochs=epochs, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.51%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test_updated, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_probs = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_classes = model.predict_classes(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce to 1d array\n",
    "# yhat_probs = yhat_probs[:, 0]\n",
    "# yhat_classes = yhat_classes[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-8ef5b59e9a54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# print('Accuracy: %f' % accuracy)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# precision tp / (tp + fp)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_updated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myhat_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Precision: %f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# recall: tp / (tp + fn)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1660\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1662\u001b[1;33m                                                  zero_division=zero_division)\n\u001b[0m\u001b[0;32m   1663\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1463\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[1;32m-> 1465\u001b[1;33m                                     pos_label)\n\u001b[0m\u001b[0;32m   1466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1467\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1275\u001b[0m                          str(average_options))\n\u001b[0;32m   1276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1277\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1278\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 93\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and binary targets"
     ]
    }
   ],
   "source": [
    "# print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test_updated, yhat_classes)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test_updated, yhat_classes)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test_updated, yhat_classes)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 15777, 32)         160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 213,705\n",
      "Trainable params: 213,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "embedding_size=32\n",
    "max_words=5000\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_size, input_length=X_train.shape[1]))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Label tensor:  (7695, 5)\n"
     ]
    }
   ],
   "source": [
    "# converting categorical variables in y_train to numerical variables\n",
    "y_train_dummies = pd.get_dummies(y_train).values\n",
    "print('Shape of Label tensor: ', y_train_dummies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 928/7695 [==>...........................] - ETA: 14:33:53 - loss: 1.1392 - accuracy: 0.6670"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-15784219303f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_dummies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#model.sav('MusicalInstrumentReviews.h5')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "model.fit(X_train, y_train_dummies, epochs=5, batch_size=32)\n",
    "#model.sav('MusicalInstrumentReviews.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('MusicalInstrumentReviews.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting categorical variables in y_train to numerical variables\n",
    "y_test_dummies = pd.get_dummies(y_test).values\n",
    "print('Shape of Label tensor: ', y_test_dummies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('MusicalInstrumentReviews.h5')\n",
    "scores = model.evaluate(X_test, y_test_dummies)\n",
    "\n",
    "LSTM_accuracy = scores[1]*100\n",
    "\n",
    "print('Test accuracy: ', scores[1]*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiation, fitting and prediction\n",
    "\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, y_train)\n",
    "predictions = MNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "MNB_f1 = round(f1_score(y_test, predictions, average='weighted'), 3)\n",
    "MNB_accuracy = round((accuracy_score(y_test, predictions)*100),2)\n",
    "\n",
    "print(\"Accuracy : \" , MNB_accuracy , \" %\")\n",
    "print(\"f1_score : \" , MNB_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiation, fitting and predictions\n",
    "\n",
    "xgb_ = xgb.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'multi:softmax',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed= 45)\n",
    "\n",
    "xgb_.fit(X_train, y_train)\n",
    "predictions = xgb_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "xgb_f1 = round(f1_score(y_test, predictions, average= 'weighted'), 3)\n",
    "xgb_accuracy = round((accuracy_score(y_test, predictions) * 100), 2)\n",
    "\n",
    "print(\"Accuracy : \" , xgb_accuracy , \" %\")\n",
    "print(\"f1_score : \" , xgb_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
